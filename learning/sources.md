# Bibliografía Anotada

## Metadatos

- `doc_id`: LEARN-SOURCES
- `purpose`: Fuentes externas usadas para definir el método.
- `status`: active
- `source_of_truth`: official
- `last_updated`: 2026-02-20
- `next_review`: 2026-03-20

## OpenAI Codex: AGENTS.md

- Fuente:
  [Custom instructions with AGENTS.md](https://developers.openai.com/codex/guides/agents-md/)
- Idea clave: descubrimiento por capas y precedencia de instrucciones.
- Cuándo aplicar: diseño de contrato operativo del repositorio.
- Limitación: no define governance local por sí sola.

## OpenAI API: reasoning best practices

- Fuente:
  [Reasoning best practices](https://developers.openai.com/api/docs/guides/reasoning-best-practices/)
- Idea clave: prompts directos y objetivos claros.
- Cuándo aplicar: tareas de decisión y validación.
- Limitación: no sustituye proceso interno del equipo.

## Anthropic: prompt engineering overview

- Fuente:
  [Prompt engineering overview](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/overview)
- Idea clave: separar contexto, instrucción y formato.
- Cuándo aplicar: plantillas de interacción con agentes.
- Limitación: guía general, requiere adaptación local.

## Anthropic: long context tips

- Fuente:
  [Long context tips](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/long-context-tips)
- Idea clave: estructurar contexto largo por secciones.
- Cuándo aplicar: repos con mucha documentación.
- Limitación: no define trazabilidad de decisiones.

## OpenAI: evals design

- Fuente: [Evals design guide](https://platform.openai.com/docs/guides/evals-design)
- Idea clave: criterios de evaluación observables.
- Cuándo aplicar: definición de checks de calidad.
- Limitación: requiere adaptación al tipo de tarea.

## Política de uso de fuentes

1. No copiar reglas sin contexto local.
1. Registrar qué fuente respalda cada decisión.
1. Revisar enlaces en cada `next_review`.
